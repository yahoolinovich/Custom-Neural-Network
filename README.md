# custom_nn

Experimental custom neural network using sigmoid activation function and back propagation. This Neural Network has two hidden layers, takes in a training set of 200 inputs from the MNIST handwritten numbers dataset and has a 72% accuracy when tested against the test data set of 10 000 images. I plan to increase the accuracy in the future by potentially adding another hidden layer, adapting the method of initializing the synaptic weights or increasing the amount of images for training.

Note: Increasing Epoch count doesn't seem to have an effect past 100 epochs.
